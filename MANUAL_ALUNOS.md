# Manual de Implementa√ß√£o - YouTube Safe Kids

## Vis√£o Geral do Projeto

O **YouTube Safe Kids** √© um sistema de filtragem de conte√∫do que utiliza modelos de Machine Learning baseados no BERTimbau para classificar coment√°rios do YouTube em diferentes categorias de seguran√ßa para crian√ßas.

### Estrutura do Projeto

```
YouTubeSafeKids-Python/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ endpoints/       # Endpoints da API (videos.py)
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py        # Configura√ß√µes principais
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ youtube.py       # Integra√ß√£o com YouTube API
‚îÇ   ‚îú‚îÄ‚îÄ nlp/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/          # Seus modelos BERTimbau
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ datasets/        # Dataset corpus.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ training/        # Scripts de treinamento
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluation/      # Scripts de avalia√ß√£o
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ utils/          # Utilit√°rios comuns
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config/         # Configura√ß√µes
‚îÇ   ‚îú‚îÄ‚îÄ filters/            # Implementa√ß√£o dos filtros
‚îÇ   ‚îú‚îÄ‚îÄ static/             # Arquivos est√°ticos (CSS, JS)
‚îÇ   ‚îî‚îÄ‚îÄ templates/          # Templates HTML
```

## Divis√£o de Tarefas

Cada aluno ser√° respons√°vel por implementar **UM** dos seguintes filtros:

1. **An√°lise de Sentimentos (AS)** - `bertimbau_sentiment.py`
2. **Detec√ß√£o de Toxicidade (TOX)** - `bertimbau_toxicity.py`
3. **Linguagem Impr√≥pria (LI)** - `bertimbau_language.py`
4. **T√≥picos Educacionais (TE)** - `bertimbau_educational.py`

---

## PASSO 1: Configura√ß√£o do Ambiente

### 1.1 Clone e Branch
```bash
# Clone o reposit√≥rio (se ainda n√£o fez)
git clone https://github.com/seu-usuario/YouTubeSafeKids-Python.git
cd YouTubeSafeKids-Python

# Crie sua branch espec√≠fica
git checkout -b feature/filtro-[SEU_FILTRO]
# Exemplo: git checkout -b feature/filtro-sentiment
```

### 1.2 Instale as Depend√™ncias
```bash
pip install -r requirements.txt
```

### 1.3 Configure as Vari√°veis de Ambiente
Crie um arquivo `.env` na raiz do projeto com as seguintes configura√ß√µes:
```bash
# YouTube API Configuration
YOUTUBE_API_KEY=sua_chave_da_api_do_youtube_aqui

# Search Configuration  
MAX_SEARCH_RESULTS=50

# Transcription Configuration
ENABLE_VIDEO_TRANSCRIPTION=True
```

**Importante**: Para obter a `YOUTUBE_API_KEY`:
1. Acesse o [Google Cloud Console](https://console.cloud.google.com/)
2. Crie um projeto ou selecione um existente
3. Ative a YouTube Data API v3
4. Gere uma chave de API

### 1.4 Verifique o Dataset
- O dataset est√° em: `app/nlp/datasets/corpus.csv`
- Cont√©m colunas: `text`, `sentiment`, `toxicity`, `language`, `educational`
- Voc√™ usar√° apenas a coluna correspondente ao seu filtro

---

## PASSO 2: An√°lise do Dataset

### 2.1 Explore Seu Dataset
```python
import pandas as pd

# Carregue o dataset
df = pd.read_csv('app/nlp/datasets/corpus.csv')

# Para An√°lise de Sentimentos - use coluna 'sentiment'
# Para Toxicidade - use coluna 'toxicity'  
# Para Linguagem Impr√≥pria - use coluna 'language'
# Para T√≥picos Educacionais - use coluna 'educational'

# Exemplo para Sentiment:
print("Distribui√ß√£o das classes:")
print(df['sentiment'].value_counts())

print("\nExemplos de textos:")
print(df[['text', 'sentiment']].head())
```

### 2.2 Entenda as Classes
- **Sentiment**: 0=Negativo, 1=Neutro, 2=Positivo
- **Toxicity**: 0=N√£o T√≥xico, 1=Levemente T√≥xico, 2=Moderadamente T√≥xico, 3=Altamente T√≥xico
- **Language**: 0=Nenhuma, 1=Leve, 2=Severa
- **Educational**: 0=N√£o Educacional, 1=Parcialmente Educacional, 2=Educacional

---

## PASSO 3: Implementa√ß√£o do Modelo

### 3.1 Localize Seu Arquivo Template
Seu arquivo est√° em `app/nlp/models/bertimbau_[SEU_FILTRO].py`

### 3.2 Implemente os M√©todos TODO

#### A. M√©todo de Pr√©-processamento
```python
def preprocess_for_[SEU_FILTRO](self, text: str) -> str:
    """
    Implemente pr√©-processamento espec√≠fico para seu dom√≠nio.
    
    Exemplos:
    - Sentiment: normalizar emoticons, tratar nega√ß√µes
    - Toxicity: mascarar palavr√µes, normalizar repeti√ß√µes
    - Language: normalizar g√≠rias, detectar disfarces
    - Educational: identificar termos t√©cnicos, conceitos
    """
    # TODO: Sua implementa√ß√£o aqui
    processed_text = text
    
    # Exemplo de implementa√ß√µes:
    # processed_text = self._normalize_emoticons(text)
    # processed_text = self._handle_negations(processed_text)
    
    return processed_text
```

#### B. M√©todo de Interpreta√ß√£o
```python
def _interpret_[SEU_FILTRO](self, predicted_class: int) -> Dict[str, Any]:
    """
    Interprete a classe predita em termos espec√≠ficos do seu dom√≠nio.
    """
    # TODO: Customize as interpreta√ß√µes para suas classes
    interpretations = {
        0: {
            'level': 'Classe 0',
            'description': 'Descri√ß√£o da classe 0',
            'recommendation': 'Recomenda√ß√£o para classe 0'
        },
        # ... adicione todas as classes
    }
    
    return interpretations.get(predicted_class, {})
```

#### C. M√©todos Auxiliares
Implemente os m√©todos auxiliares marcados com TODO conforme necess√°rio para seu dom√≠nio.

---

## PASSO 4: Prepara√ß√£o dos Dados

### 4.1 Script de Prepara√ß√£o
Crie um script para preparar seus dados **na pasta `app/nlp/datasets/`**:

```python
# prepare_data_[SEU_FILTRO].py
import pandas as pd
from sklearn.model_selection import train_test_split

def prepare_data():
    # Carrega dataset
    df = pd.read_csv('app/nlp/datasets/corpus.csv')
    
    # Seleciona colunas relevantes (substitua 'sentiment' pela sua coluna)
    texts = df['text'].tolist()
    labels = df['sentiment'].tolist()  # Mude para sua coluna
    
    # Divis√£o: 80% treino, 10% valida√ß√£o, 10% teste
    train_texts, temp_texts, train_labels, temp_labels = train_test_split(
        texts, labels, test_size=0.2, random_state=42, stratify=labels
    )
    
    val_texts, test_texts, val_labels, test_labels = train_test_split(
        temp_texts, temp_labels, test_size=0.5, random_state=42, stratify=temp_labels
    )
    
    return train_texts, train_labels, val_texts, val_labels, test_texts, test_labels

if __name__ == "__main__":
    train_texts, train_labels, val_texts, val_labels, test_texts, test_labels = prepare_data()
    
    print(f"Treino: {len(train_texts)} amostras")
    print(f"Valida√ß√£o: {len(val_texts)} amostras") 
    print(f"Teste: {len(test_texts)} amostras")
```

---

## PASSO 5: Treinamento do Modelo

### 5.1 Script de Treinamento
Crie o script de treinamento **na pasta `app/nlp/training/`**:

```python
# train_[SEU_FILTRO].py
import logging
from app.nlp.models.bertimbau_[SEU_FILTRO] import Bertimbau[SeuFiltro]
from app.nlp.datasets.prepare_data_[SEU_FILTRO] import prepare_data

# Configura√ß√£o de logging
logging.basicConfig(level=logging.INFO)

def main():
    # Prepara dados
    train_texts, train_labels, val_texts, val_labels, test_texts, test_labels = prepare_data()
    
    # Cria modelo
    model = Bertimbau[SeuFiltro]()  # Substitua pelo nome da sua classe
    
    # Treina modelo
    results = model.train_model(
        train_texts=train_texts,
        train_labels=train_labels,
        val_texts=val_texts,
        val_labels=val_labels,
        config_name='default',
        experiment_name='[seu_filtro]_v1'
    )
    
    print("Treinamento conclu√≠do!")
    print(f"Modelo salvo em: {results['model_path']}")
    print(f"M√©tricas finais: {results['final_metrics']}")

if __name__ == "__main__":
    main()
```

### 5.2 Execute o Treinamento
```bash
cd app/nlp/training
python train_[SEU_FILTRO].py
```

---

## PASSO 6: Avalia√ß√£o do Modelo

### 6.1 Script de Avalia√ß√£o
Crie o script de avalia√ß√£o **na pasta `app/nlp/evaluation/`**:

```python
# evaluate_[SEU_FILTRO].py
from app.nlp.models.bertimbau_[SEU_FILTRO] import Bertimbau[SeuFiltro]
from app.nlp.evaluation.model_evaluator import ModelEvaluator
from app.nlp.datasets.prepare_data_[SEU_FILTRO] import prepare_data

def main():
    # Prepara dados de teste
    _, _, _, _, test_texts, test_labels = prepare_data()
    
    # Carrega modelo treinado
    model_path = "caminho/para/seu/modelo/treinado"  # Ajuste conforme necess√°rio
    model = Bertimbau[SeuFiltro](model_path=model_path)
    
    # Cria avaliador
    evaluator = ModelEvaluator(task_name='[SEU_FILTRO]')
    
    # Avalia modelo
    results = evaluator.evaluate_model(
        model=model,
        test_texts=test_texts,
        test_labels=test_labels,
        save_results=True,
        experiment_name='[seu_filtro]_evaluation'
    )
    
    print("Avalia√ß√£o conclu√≠da!")
    print(f"Acur√°cia: {results['accuracy']:.4f}")
    print(f"F1-Score: {results['f1_macro']:.4f}")

if __name__ == "__main__":
    main()
```

---

## PASSO 7: Testes e Valida√ß√£o

### 7.1 Teste Seu Modelo
Crie o script de teste **na pasta `tests/` (crie a pasta se n√£o existir) ou `app/nlp/utils/`**:

```python
# test_[SEU_FILTRO].py
from app.nlp.models.bertimbau_[SEU_FILTRO] import Bertimbau[SeuFiltro]

def test_model():
    # Carrega modelo
    model = Bertimbau[SeuFiltro](model_path="caminho/para/modelo")
    
    # Textos de teste
    test_texts = [
        "Exemplo de texto 1",
        "Exemplo de texto 2", 
        "Exemplo de texto 3"
    ]
    
    # Testa predi√ß√µes individuais
    for text in test_texts:
        result = model.predict_[seu_metodo_principal](text)
        print(f"Texto: {text}")
        print(f"Predi√ß√£o: {result}")
        print("-" * 50)
    
    # Testa predi√ß√£o em lote
    batch_results = model.analyze_[seu_filtro]_batch(test_texts)
    print(f"Resultados em lote: {len(batch_results)} predi√ß√µes")

if __name__ == "__main__":
    test_model()
```

---

## PASSO 8: Implementa√ß√£o do Filtro

### 8.1 Implemente o Filtro Final
Ap√≥s treinar e validar seu modelo, implemente o filtro em `app/filters/[seu_filtro].py`:

```python
# app/filters/[seu_filtro].py
from typing import Dict, Any, List
from ..nlp.models.bertimbau_[SEU_FILTRO] import Bertimbau[SeuFiltro]

class [SeuFiltro]Filter:
    """
    Filtro de [Seu Filtro] para o YouTube Safe Kids.
    """
    
    def __init__(self, model_path: str = None):
        self.model = Bertimbau[SeuFiltro](model_path=model_path)
        self.filter_name = "[SEU_FILTRO]"
    
    def filter_comment(self, comment: str) -> Dict[str, Any]:
        """
        Filtra um coment√°rio individual.
        """
        result = self.model.predict_[seu_metodo_principal](comment)
        
        return {
            'filter_name': self.filter_name,
            'is_safe': self._is_safe(result),
            'confidence': result['confidence'],
            'details': result
        }
    
    def filter_comments_batch(self, comments: List[str]) -> List[Dict[str, Any]]:
        """
        Filtra m√∫ltiplos coment√°rios.
        """
        results = self.model.analyze_[seu_filtro]_batch(comments)
        
        return [
            {
                'filter_name': self.filter_name,
                'is_safe': self._is_safe(result),
                'confidence': result['confidence'],
                'details': result
            }
            for result in results
        ]
    
    def _is_safe(self, result: Dict[str, Any]) -> bool:
        """
        Determina se o conte√∫do √© seguro baseado na predi√ß√£o.
        
        TODO: Customize esta l√≥gica para seu filtro espec√≠fico
        """
        # Exemplo: para sentiment, pode ser seguro se n√£o for muito negativo
        # Para toxicity, seguro se n√£o for t√≥xico
        # Customize conforme necess√°rio
        predicted_class = result['predicted_class']
        
        # Exemplo de l√≥gica (ajuste para seu caso):
        safe_classes = [0, 1]  # Classes consideradas seguras
        return predicted_class in safe_classes
```

---

## PASSO 9: Documenta√ß√£o e Testes

### 9.1 Documente Seu Trabalho
Crie um arquivo `README_[SEU_FILTRO].md` documentando:
- Abordagem utilizada
- Pr√©-processamentos aplicados
- Resultados obtidos
- Dificuldades encontradas
- Melhorias futuras

### 9.2 Testes Finais
```python
# final_test_[SEU_FILTRO].py
from app.filters.[seu_filtro] import [SeuFiltro]Filter

def test_filter():
    # Cria filtro
    filter_obj = [SeuFiltro]Filter(model_path="caminho/para/modelo")
    
    # Testa coment√°rios diversos
    test_comments = [
        "Coment√°rio positivo de teste",
        "Coment√°rio negativo de teste",
        "Coment√°rio neutro de teste"
    ]
    
    for comment in test_comments:
        result = filter_obj.filter_comment(comment)
        print(f"Coment√°rio: {comment}")
        print(f"√â seguro: {result['is_safe']}")
        print(f"Confian√ßa: {result['confidence']:.4f}")
        print("-" * 50)

if __name__ == "__main__":
    test_filter()
```

---

## PASSO 10: Integra√ß√£o e Entrega

### 10.1 Prepare para Merge
```bash
# Adicione todos os arquivos
git add .

# Commit suas mudan√ßas
git commit -m "Implementa filtro de [SEU_FILTRO] com modelo BERTimbau"

# Push para sua branch
git push origin feature/filtro-[SEU_FILTRO]
```

### 10.2 Crie Pull Request
1. V√° para o reposit√≥rio no GitHub
2. Crie um Pull Request da sua branch para `main`
3. Descreva suas implementa√ß√µes e resultados
4. Aguarde review e aprova√ß√£o

---

## Dicas Importantes

### ‚úÖ Boas Pr√°ticas
- **Sempre teste** seu c√≥digo antes de fazer commit
- **Documente** suas decis√µes e implementa√ß√µes
- **Use logging** para acompanhar o treinamento
- **Valide** seus resultados com dados de teste
- **Mantenha** c√≥digo limpo e comentado

### ‚ö†Ô∏è Cuidados
- **N√£o modifique** arquivos de outros alunos
- **N√£o altere** a classe base `BertimbauBase`
- **N√£o commite** modelos treinados (s√£o muito grandes)
- **N√£o altere** as configura√ß√µes principais em `app/core/config.py` sem consultar
- **N√£o modifique** a integra√ß√£o com YouTube API em `app/core/youtube.py`
- **Teste** em dados pequenos primeiro
- **Monitore** o uso de mem√≥ria durante treinamento

### üîß Troubleshooting
- **Erro de mem√≥ria**: Reduza batch_size ou max_length
- **Treinamento lento**: Use GPU se dispon√≠vel
- **Baixa acur√°cia**: Ajuste pr√©-processamento ou hiperpar√¢metros
- **Erro de import**: Verifique PYTHONPATH e estrutura de pastas
- **Erro de API do YouTube**: Verifique se a `YOUTUBE_API_KEY` est√° configurada corretamente
- **Problemas de transcri√ß√£o**: Verifique se `ENABLE_VIDEO_TRANSCRIPTION=True` no arquivo `.env`

---

## Recursos Adicionais

### Configura√ß√µes Dispon√≠veis
- Configura√ß√µes de modelo: `app/nlp/config/model_config.py`
- Configura√ß√µes de treinamento: `app/nlp/config/training_config.py`

### Utilit√°rios Dispon√≠veis
- Processamento de dados: `app/nlp/utils/data_utils.py`
- Helpers de treinamento: `app/nlp/utils/training_utils.py`
- Avalia√ß√£o: `app/nlp/evaluation/model_evaluator.py`

### Contato
- Para d√∫vidas t√©cnicas: [seu-email@exemplo.com]
- Para problemas de ambiente: [suporte@exemplo.com]

---

**Boa sorte com sua implementa√ß√£o! üöÄ**

Lembre-se: o objetivo √© criar um filtro eficaz que contribua para tornar o YouTube mais seguro para crian√ßas. Cada filtro √© uma pe√ßa importante do quebra-cabe√ßa final!